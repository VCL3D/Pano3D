<!Doctype html>
<html lang="en">
    <head>
        <title>Pano3d: A Holistic Benchmark and a Solid Baseline for 360<sup>o</sup> Depth Estimation</title>

        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="author" content="Georgios Albanis">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <!-- <link rel="icon" type="image/png" href="data/bunny.png"/> -->

        <link rel="stylesheet" type="text/css" href="style_project_page.css?cache=7733391418498779679">
        <link href="https://fonts.googleapis.com/css?family=Arvo|Roboto&display=swap" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
        <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
        <link rel="stylesheet" href="https://unpkg.com/@glidejs/glide/dist/css/glide.core.min.css">
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script src="https://unpkg.com/@glidejs/glide"></script>
        <style type="text/css">
            .side-text {
                width:60%;
                display:inline-block;
                vertical-align:top;
            }
            .side-image {
                width: 38%;
                display: inline-block;
                vertical-align: top;
            }
            .controls {
                margin-bottom: 10px;
            }
            .left-controls {
                display: inline-block;
                vertical-align: top;
                width: 80%;
            }
            .right-controls {
                display: inline-block;
                vertical-align: top;
                width: 19%;
                text-align: right;
            }
            .render_window {
                display: inline-block;
                vertical-align: middle;
                box-shadow: 1px 0px 5px black;
                margin-right: 10px;
                margin-bottom: 10px;
                width: calc(33% - 10px);
            }
            .progress {
                background: #666;
                position: relative;
                height: 5px;
                margin-bottom: -5px;
                display: none;
            }
            .glide__slide:hover {cursor: grab;}
            .glide__slide:active {cursor: grabbing;}
            .glide__slide img {width: 90%;}
            .glide__bullets {
                text-align: center;
            }
            .glide__bullet--active {
                color: #aaa; 
            }

            @media (max-width: 400px) {
                .render_window {
                    display: block;
                    width: 90%;
                    margin: 10px auto;
                }
            }
            @media (max-width: 700px) {
                .side-image {
                    display: block;
                    width: 80%;
                    margin: 10px auto;
                }
                .side-text {
                    display: block;
                    width: 100%;
                }
            }
        </style>
    </head>
    <body>
        <div class="section">
            <h1 class="project-title">
                Pano3d: A Holistic Benchmark and a Solid Baseline for 360<sup>o</sup> Depth Estimation
            </h1>
            <div class="authors">
                <a href=https://tzole1155.github.io/>
                    Georgios Albanis <sup>1</sup>
                </a>
                <a href=https://zokin.github.io/>
                    Nikolaos Zioulis <sup>1,2</sup>
                </a>
                <a href=https://github.com/pdrak/>
                    Petros Drakoulis <sup>1</sup>
                </a>
                <a href=https://github.com/VasilisGks/>
                        Vasileios Gkitsas <sup>1</sup>
                </a>
                <a href=https://github.com/vladsterz/>
                        Vladimiros Sterzentsenko  <sup>1</sup>
                </a>
                <a href=http://www.gatv.ssr.upm.es//>
                        Federico Alvarez  <sup>2</sup>
                </a>
                <a href=https://www.iti.gr/iti/people/Dimitrios_Zarpalas.html/>
                        Dimitrios Zarpalas <sup>2</sup>
                </a>
                <a href=https://www.iti.gr/iti/people/Petros_Daras.html/>
                        Petros Daras <sup>2</sup>
                    </a>
            </div>

            <div class="affiliations">
                <span><sup>1</sup> Visual Computing Lab (VCL), Information Technologies Institute (ITI), Centre for Research and Technology Hellas (CERTH), Thessaloniki, Greece</span><br>
                <span><sup>2</sup> Signals, Systems and Radiocommunications Department (SSRD), Universidad Polit√©cnica de Madrid (UPM), Madrid, Spain</span> <br/>
            </div>

            <div class="project-conference">
                OmniCV 2021
            </div>

            <div class="project-icons">
                <!-- <a href="https://arxiv.org/pdf/2103.10429.pdf"> -->
                    <i class="fa fa-file"></i> <br/>
                    Paper
                </a>
                <!-- <a href="https://github.com/paschalidoud/neural_parts"> -->
                    <i class="fa fa-github"></i> <br/>
                    Code
                </a>
                <!--<a href="https://www.youtube.com/watch?v=QgD0NHbWVlU&vq=hd1080&autoplay=1">
                    <i class="fa fa-youtube-play"></i> <br/>
                    Video
                </a>-->
                <!--<a href="https://paschalidoud.github.io/data/Paschalidou2020CVPR_poster.pdf">
                    <i class="fa fa-picture-o"></i> <br/>
                    Poster
                </a>
                <a href="http://www.cvlibs.net/publications/Paschalidou2020CVPR_slides.pdf">
                    <i class="fa fa-file-powerpoint-o"></i> <br/>
                    Slides
                </a>
                <a href="https://autonomousvision.github.io/hierarchical-primitives/">
                    <i class="fa fa-newspaper-o"></i> <br/>
                    Blog
                </a>-->
            </div>

            <div class="teaser-image">
                <img src="pano3d/teaser.png" style="width:100%;">
                <p class="caption">Preserving depth's piece-wise smoothness should be the primary goal of data-driven depth estimation models.
                    Yet most works only assess direct depth performance neglecting secondary traits like smoothness or boundary preservation.
                    Different architectures (UNet -- left, or Pnas -- right) exhibit different inference characteristics skewed towards boundaries (UNet) or smoothness (Pnas).
                    The Pano3D benchmark descends from a holistic perspective taking into account all performance traits, and additionally focuses on an orthogonal performance direction, generalization to unseen data from different distributions, contexts or domains. </p>
                <!-- <figure style="width: 49%;">
                    <video class="centered" width="100%" controls muted loop autoplay>
                        <source src="projects/neural_parts/motivation_cvxnet.mp4" type="video/mp4"/>
                    </video>
                    <p class="caption">Existing primitive-based methods rely on
                    simple shapes for decomposing complex 3D shapes into
                    parts. As a result, they <strong>require a large number of primitives</strong>
                    for extracting accurate reconstructions. However, this results in <strong>
                    less interpretable shape abstractions</strong>, namely
                    <strong>primitives are not semantically meaningful parts</strong>.</p>
                </figure>
                <figure style="width: 49%;">
                    <video class="centered" width="100%" controls muted loop autoplay>
                        <source src="projects/neural_parts/motivation_ours.mp4" type="video/mp4"/>
                    </video>
                    <p class="caption">Neural Parts is a novel 3D primitive representation that can 
                    <strong>represent arbitrarily complex genus-zero shapes
                    </strong> and thus yield more <strong>geometrically accurate</strong> and
                    <strong>semantically meaningful</strong> shape abstractions compared to simpler primitives.</p>
                </figure> -->
            </div>

            <!-- <div class="section-title">Approach Overview</div>
            <div class="content">
                <div class="side-text"><p>Primitive-based representations seek to infer
                <strong>semantically consistent part arrangements across
                different object instances</strong>. Existing primitive-based
                methods rely on simple shapes for decomposing complex objects
                into parts such as cuboids, superquadrics, spheres or
                convexes. <strong>Due to their simple parametrization, these primitives
                have limited expressivity and cannot capture arbitrarily
                complex geometries</strong>. Therefore, <strong>existing part-based methods
                require a large number of primitives for extracting
                geometrically accurate reconstructions</strong>. However, using <strong>more
                primitives comes at the expense of less interpretable
                reconstructions</strong>. Namely, a primitive is not an identifiable
                part anymore.</p></div>
                <div class="side-image"><img src="pano3d/teaser.png" style="width:100%;"></div>
                <p>We introduce a novel 3D primitive representation that is
                defined as <strong>a deformation between shapes</strong> and is
                <strong>parametrized as a learned homeomorphic mapping</strong>
                implemented with an <strong>Invertible Neural Network
                (INN)</strong>. We argue that a primitive should be a non
                trivial genus-zero shape with well defined implicit and explicit representations. Using an INN allows us to efficiently compute
                the implicit and explicit representation of the predicted shape
                and impose various constraints on the predicted parts. In contrast to prior work,
                that directly predict the primitive parameters (i.e. centroids and sizes for cuboids
                and superquadrics and hyperplanes for convexes), we employ the INN to fully define each primitive.
                This allows us to have primitives that capture arbitrarily
                complex geometries, hence the ability of our model to parse
                objects into expressive shape abstractions that are more
                geometrically accurate using an order of magnitude fewer
                primitives compared to approaches that rely on simple convex
                shape primitives.
                </p>
                <img src="pano3d/teaser.png" style="width:100%;">
                <p class="caption">Given an input image and a watertight mesh
                of the target object we seek to learn a representation with M
                primitives that best describes the target object. We define our
                primitives via a deformation between shapes that is
                parametrized as a learned homeomorphism implemented with an
                Invertible Neural Network (INN). For each primitive, we seek to
                learn a homeomorphism between the 3D space of a simple
                genus-zero shape and the 3D space of the target object, such
                that the deformed shape matches a part of the target object. Due
                to its simple implicit surface definition and tesselation, we
                employ a sphere as our genus-zero shape. Note that using an INN
                allows us to efficiently compute the implicit and explicit representation of
                the predicted shape and impose various constraints on the predicted parts.</p>
            </div> -->

            <div class="section-title">Results</div>
            <div class="content">
                In the following interactive visualization, we provide qualitative results for our best model.

                <h3>Input Panoramas</h3>
                <div id="input_panoramas">
                    <div class="render_container">
                        <div data-size="400" class="render_window"></div><div data-size="400" class="render_window"></div><div data-size="400" class="render_window"></div>
                    </div>
                </div>

                <h3>Predicted meshes</h3>
                <div id="pred_meshes">
                    <div class="render_container">
                        <div data-size="400" class="render_window"></div><div data-size="400" class="render_window"></div><div data-size="400" class="render_window"></div>
                    </div>
                </div>

                <!-- <h3>Textured meshes</h3>
                <div id="point_clouds">
                    <div class="render_container">
                        <div data-size="400" class="render_window"></div><div data-size="400" class="render_window"></div><div data-size="400" class="render_window"></div>
                    </div>
                </div> -->
                
                <!-- <h3>Humans</h3>
                <div id="humans">
                    <div class="controls">
                        <div class="left-controls">
                            Show
                            <input type="checkbox" id="humans_all" checked><label for="humans_all">all parts</label>
                            <input type="checkbox" id="humans_head"><label for="humans_head">heads</label>
                            <input type="checkbox" id="humans_body"><label for="humans_body">bodies</label>
                            <input type="checkbox" id="humans_left_hand"><label for="humans_left_hand">left-arms</label>
                            <input type="checkbox" id="humans_right_hand"><label for="humans_right_hand">right-arms</label>
                            <input type="checkbox" id="humans_left_leg"><label for="humans_left_leg">left-legs</label>
                            <input type="checkbox" id="humans_right_leg"><label for="humans_right_leg">right-legs</label>
                        </div>
                        <div class="right-controls">
                            <button>Randomize</button>
                        </div>
                    </div>
                    <div class="render_container">
                        <div data-size="400" class="render_window"></div><div data-size="400" class="render_window"></div><div data-size="400" class="render_window"></div>
                    </div>
                </div>

                <h3>Planes</h3>
                <div id="planes">
                    <div class="controls">
                        <div class="left-controls">
                            Show
                            <input type="checkbox" id="planes_all" checked><label for="planes_all">all parts</label>
                            <input type="checkbox" id="planes_nose"><label for="planes_nose">noses</label>
                            <input type="checkbox" id="planes_body"><label for="planes_body">bodies</label>
                            <input type="checkbox" id="planes_left_wing"><label for="planes_left_wing">left-wings</label>
                            <input type="checkbox" id="planes_right_wing"><label for="planes_right_wing">right-wings</label>
                            <input type="checkbox" id="planes_tail"><label for="planes_tail">tails</label>
                        </div>
                        <div class="right-controls">
                            <button>Randomize</button>
                        </div>
                    </div>
                    <div class="render_container">
                        <div data-size="400" class="render_window"></div><div data-size="400" class="render_window"></div><div data-size="400" class="render_window"></div>
                    </div>
                </div> -->
            </div>

            <!-- <div class="section-title">Comparison to Primitive-based Methods</div>
            <div class="content">
                <p>
                    We compare the representation power of Neural Parts to
                    other primitive-based methods by evaluating the
                    reconstruction quality with varying number of primitives on
                    three datasets. We observe that our model is <strong>more
                    geometrically accurate, more semantically consistent and
                    yields more meaningful parts</strong> (i.e. primitives are
                    identifiable parts such as thumbs, legs, wings, tires,
                    etc.) compared to simpler primitives.
                </p>
                <div class="glide">
                    <div class="glide__bullets" data-glide-el="controls[nav]">
                        <button class="glide__bullet" data-glide-dir="=0">Humans</button>
                        <button class="glide__bullet" data-glide-dir="=1">Hands</button>
                        <button class="glide__bullet" data-glide-dir="=2">Chairs</button>
                        <button class="glide__bullet" data-glide-dir="=3">Planes</button>
                        <button class="glide__bullet" data-glide-dir="=4">Cars</button>
                        <button class="glide__bullet" data-glide-dir="=5">Lamps</button>
                    </div>
                    <div class="glide__track" data-glide-el="track">
                        <ul class="glide__slides">
                            <li class="glide__slide"><img src="projects/neural_parts/comparison/humans.png"></li>
                            <li class="glide__slide"><img src="projects/neural_parts/comparison/hands.png"></li>
                            <li class="glide__slide"><img src="projects/neural_parts/comparison/chairs.png"></li>
                            <li class="glide__slide"><img src="projects/neural_parts/comparison/planes.png"></li>
                            <li class="glide__slide"><img src="projects/neural_parts/comparison/cars.png"></li>
                            <li class="glide__slide"><img src="projects/neural_parts/comparison/lamps.png"></li>
                        </ul>
                    </div>
                </div>
            </div>

            <div class="section-title">Semantic Consistency</div>
            <div class="content">
                We observe that Neural Parts consistently use the same
                primitive for representing the same object part regardless of
                the breadth of the part's motion. Notably, this
                <strong>temporal consistency is an emergent property</strong>
                of our method and <strong>not one that is enforced with any
                kind of loss</strong>.
                <video class="centered" width="100%" controls muted loop autoplay>
                    <source
                        src="projects/neural_parts/semantic-consistency-shorter.mp4"
                        type="video/mp4" />
                </video>
            </div> -->

            <div class="section-title">Acknowledgements</div>
            <div class="content">
                This project has received funding from the European Union‚Äôs Horizon 2020 innovation programme <a href="https://atlantis-ar.eu/">ATLANTIS</a> under grant agreement No 951900.
            </div>
        </div>

        <script type="module">
            import * as THREE from "https://unpkg.com/three/build/three.module.js";
            import { OrbitControls } from "https://unpkg.com/three/examples/jsm/controls/OrbitControls.js";
            import {OBJLoader} from "https://unpkg.com/three/examples/jsm/loaders/OBJLoader.js";
            import { PLYLoader } from './js/loaders/PLYLoader.js';
            import { MTLLoader } from "https://unpkg.com/three/examples/jsm/loaders/MTLLoader"

            // Render the predictions
            function random_choice(arr, n) {
                var index_set = {};
                var choice = [];
                while (choice.length < n) {
                    var idx = Math.floor(Math.random() * arr.length);
                    if (index_set[idx] !== undefined) {
                        continue;
                    }
                    index_set[idx] = 0;
                    choice.push(idx);
                }

                return choice.map(x => arr[x]);
            }

            function progress_bar() {
                var el = document.createElement("div");
                el.classList.add("progress");

                return {
                    domElement: el,
                    update: function (percent) {
                        percent = Math.min(1, Math.max(0, percent));
                        el.style.display = "block";
                        el.style.width = Math.round(percent * 100) + "%";
                    },
                    hide: function () {
                        el.style.display = "none";
                    }
                };
            }

            function reset_checkboxes(checkboxes) {
                Array.prototype.forEach.call(checkboxes, function (c) {
                    c.checked = false;
                });
                checkboxes[0].checked = true;
            }

            function show_ply(el,prefix,N){
                const scene = new THREE.Scene();
                const renderer = new THREE.WebGLRenderer();
                const camera = new THREE.PerspectiveCamera(75, 1, 0.1, 1000);
                const controls = new OrbitControls(camera, renderer.domElement);

                camera.position.set(0.5, 0.5, 0.5);
                controls.target.set(0, 0, 0);
                controls.autoRotate = true;
                controls.autoRotateSpeed = 4;
                scene.background = new THREE.Color("white");
                var size = el.dataset.size;
                renderer.setSize(size, size);
                var progress = progress_bar();
                el.appendChild(progress.domElement);
                el.appendChild(renderer.domElement);

                const amb_light = new THREE.AmbientLight(0x606060); // soft white light
                scene.add(amb_light);
                const hem_light = new THREE.HemisphereLight(0xffffbb, 0x080820, 0.5);
                scene.add(hem_light);

                var previous_canvas_size = size;
                function animate() {
                    requestAnimationFrame(animate);
                    if (el.offsetWidth != previous_canvas_size) {
                        previous_canvas_size = el.offsetWidth;
                        renderer.domElement.style.width = previous_canvas_size + "px";
                        renderer.domElement.style.height = previous_canvas_size + "px";
                    }

                    controls.update();
                    renderer.render(scene, camera);
                }

                const loader = new OBJLoader();
                var meshes = [];
                var progresses = [];
                var loaded = 0;
                function load_ply(ply_idx) {
                    progresses[ply_idx] = 0;
                    loader.load( 'ply/pred_0_mesh.obj', function ( geometry ) {
                        //var geometry = object.children[0].geometry;
                        //geometry.computeVertexNormals();
                        var material = new THREE.MeshStandardMaterial( { color: 0xffffff, specular: 0x111111, shininess: 200 } );
                        material.transparent = true;
                        var mesh = new THREE.Mesh( geometry, material );
                        //mesh.position.y = - 0.2;
                        //mesh.position.z = 0.3;
                        //mesh.rotation.x = - Math.PI / 2;
                        //mesh.scale.multiplyScalar( 0.001 );
                        mesh.castShadow = true;
                        mesh.receiveShadow = true;
                        meshes[ply_idx] = mesh;
                        scene.add( mesh );
                        loaded++;
                        if (loaded == N) {
                            progress.hide();
                        }
                    });
                }
                for (var i=0; i<N; i++) {
                    load_ply(i);
                }
                animate();
                return {
                    meshes: meshes,
                    show: function (indices) {
                        for (var i=0; i<N; i++) {
                            meshes[i].material.opacity = 0.5;
                            //meshes[i].visible = false;
                        }
                        for (var i=0; i<indices.length; i++) {
                            meshes[indices[i]].material.opacity = 1;
                            //meshes[indices[i]].visible = true;
                        }
                    },
                    show_all: function () {
                        for (var i=0; i<N; i++) {
                            meshes[i].material.opacity = 1;
                            //meshes[i].visible = true;
                        }
                    },
                    set_size: function(width, height) {
                        renderer.setSize(width, height);
                    }
                };

            }

            function show_mesh(el,prefix,N){

                const scene = new THREE.Scene();
                const renderer = new THREE.WebGLRenderer();
                const camera = new THREE.PerspectiveCamera(75, 1, 0.1, 1000);
                const controls = new OrbitControls(camera, renderer.domElement);

                camera.position.set(0.5, 0.5, 0.5);
                controls.target.set(0, 0, 0);
                controls.autoRotate = true;
                controls.autoRotateSpeed = 4;
                scene.background = new THREE.Color("white");
                var size = el.dataset.size;
                renderer.setSize(size, size);
                var progress = progress_bar();
                el.appendChild(progress.domElement);
                el.appendChild(renderer.domElement);

                const amb_light = new THREE.AmbientLight(0x606060); // soft white light
                scene.add(amb_light);
                const hem_light = new THREE.HemisphereLight(0xffffbb, 0x080820, 0.5);
                scene.add(hem_light);

                var previous_canvas_size = size;
                function animate() {
                    requestAnimationFrame(animate);
                    if (el.offsetWidth != previous_canvas_size) {
                        previous_canvas_size = el.offsetWidth;
                        renderer.domElement.style.width = previous_canvas_size + "px";
                        renderer.domElement.style.height = previous_canvas_size + "px";
                    }

                    controls.update();
                    renderer.render(scene, camera);
                }

                const mtlLoader = new MTLLoader();
                var meshes = [];
                var progresses = [];
                var loaded = 0;
                function load_mesh(mesh_idx) {
                    progresses[mesh_idx] = 0;
                    mtlLoader.load(prefix.replace("obj","mtl"),
                    // mtlLoader.load('ply/pred_0_mesh.mtl',
                    (materials) => {
                            materials.preload();

                            const objLoader = new OBJLoader();
                            objLoader.setMaterials(materials);
                            objLoader.load(prefix,
                            (object) => {
                                scene.add(object);
                                meshes[mesh_idx] = object;
                            },)
                    });
                }
                for (var i=0; i<N; i++) {
                    load_mesh(i);
                }
                animate();
                return {
                    meshes: meshes,
                    show: function (indices) {
                        for (var i=0; i<N; i++) {
                            meshes[i].material.opacity = 0.5;
                            //meshes[i].visible = false;
                        }
                        for (var i=0; i<indices.length; i++) {
                            meshes[indices[i]].material.opacity = 1;
                            //meshes[indices[i]].visible = true;
                        }
                    },
                    show_all: function () {
                        for (var i=0; i<N; i++) {
                            meshes[i].material.opacity = 1;
                            //meshes[i].visible = true;
                        }
                    },
                    set_size: function(width, height) {
                        renderer.setSize(width, height);
                    }
                };
        }

            function show_object(el, prefix, N) {
                const scene = new THREE.Scene();
                const renderer = new THREE.WebGLRenderer();
                const camera = new THREE.PerspectiveCamera(75, 1, 0.1, 1000);
                const controls = new OrbitControls(camera, renderer.domElement);

                camera.position.set(0.5, 0.5, 0.5);
                controls.target.set(0, 0, 0);
                controls.autoRotate = true;
                controls.autoRotateSpeed = 4;
                scene.background = new THREE.Color("white");
                var size = el.dataset.size;
                renderer.setSize(size, size);
                var progress = progress_bar();
                el.appendChild(progress.domElement);
                el.appendChild(renderer.domElement);

                const amb_light = new THREE.AmbientLight(0x606060); // soft white light
                scene.add(amb_light);
                const hem_light = new THREE.HemisphereLight(0xffffbb, 0x080820, 0.5);
                scene.add(hem_light);

                const colors = [
                    0x1f77b4,
                    0xaec7e8,
                    0xff7f0e,
                    0xffbb78,
                    0x2ca02c,
                    0x98df8a,
                    0xd62728,
                    0xff9896,
                    0x9467bd,
                    0xc5b0d5,
                    0x8c564b,
                    0xc49c94,
                    0xe377c2,
                    0xf7b6d2,
                    0x7f7f7f,
                    0xc7c7c7,
                    0xbcbd22,
                    0xdbdb8d,
                    0x17becf,
                    0x9edae5
                ];
                var previous_canvas_size = size;
                function animate() {
                    requestAnimationFrame(animate);
                    if (el.offsetWidth != previous_canvas_size) {
                        previous_canvas_size = el.offsetWidth;
                        renderer.domElement.style.width = previous_canvas_size + "px";
                        renderer.domElement.style.height = previous_canvas_size + "px";
                    }

                    controls.update();
                    renderer.render(scene, camera);
                }

                const loader = new OBJLoader();
                var meshes = [];
                var progresses = [];
                var loaded = 0;
                function load_part(part_idx) {
                    progresses[part_idx] = 0;
                    loader.load(
                        prefix,
                        function (object) {
                            //var g = geometry;
                            //var m = new THREE.MeshLambertMaterial({color: 0x111111});
                            //m.transparent = true;
                            //var mesh = new THREE.Mesh(g, m);
                            meshes[part_idx] = object;
                            scene.add(object);

                            loaded++;
                            if (loaded == N) {
                                progress.hide();
                            }
                        },
                    );
                }
                for (var i=0; i<N; i++) {
                    load_part(i);
                }
                animate();

                return {
                    meshes: meshes,
                    show: function (indices) {
                        for (var i=0; i<N; i++) {
                            meshes[i].material.opacity = 0.5;
                            //meshes[i].visible = false;
                        }
                        for (var i=0; i<indices.length; i++) {
                            meshes[indices[i]].material.opacity = 1;
                            //meshes[indices[i]].visible = true;
                        }
                    },
                    show_all: function () {
                        for (var i=0; i<N; i++) {
                            meshes[i].material.opacity = 1;
                            //meshes[i].visible = true;
                        }
                    },
                    set_size: function(width, height) {
                        renderer.setSize(width, height);
                    }
                };
            }


            function show_pano(el,prefix,N){
				const scene = new THREE.Scene();
                const renderer = new THREE.WebGLRenderer();
                const camera = new THREE.PerspectiveCamera(75, 1, 0.1, 1000);
				const geometry = new THREE.SphereGeometry( 500, 60, 40 );
                const controls = new OrbitControls(camera, renderer.domElement);
				camera.position.set(0.5, 0.5, 0.5);
                controls.target.set(0, 0, 0);
                controls.autoRotate = true;
                controls.autoRotateSpeed = 4;
                scene.background = new THREE.Color("white");
				var size = el.dataset.size;
                renderer.setSize(size, size);
                var progress = progress_bar();
                el.appendChild(progress.domElement);
                el.appendChild(renderer.domElement);
				// invert the geometry on the x-axis so that all of the faces point inward
				geometry.scale( - 1, 1, 1 );

				var previous_canvas_size = size;
                function animate() {
                    requestAnimationFrame(animate);
                    if (el.offsetWidth != previous_canvas_size) {
                        previous_canvas_size = el.offsetWidth;
                        renderer.domElement.style.width = previous_canvas_size + "px";
                        renderer.domElement.style.height = previous_canvas_size + "px";
                    }

                    controls.update();
                    renderer.render(scene, camera);
                }

				var meshes = [];
                var progresses = [];
                var loaded = 0;

				function load_pano(pano_idx){
					progresses[pano_idx] = 0;
                    //console.log("dpepdle" + prefix);
					//var texture = new THREE.TextureLoader().load( 'panoramas/color_0.png' );
                    var texture = new THREE.TextureLoader().load(prefix);
					var material = new THREE.MeshBasicMaterial( { map: texture } );

					var mesh = new THREE.Mesh( geometry, material );
					meshes[pano_idx] = mesh;
					scene.add( mesh );
					loaded++;
                    if (loaded == N) {
                        progress.hide();
                    }
				}
				for (var i=0; i<N; i++) {
                    load_pano(i);
                }
                animate();

				return {
                    meshes: meshes,
                    show: function (indices) {
                        for (var i=0; i<N; i++) {
                            meshes[i].material.opacity = 0.5;
                            //meshes[i].visible = false;
                        }
                        for (var i=0; i<indices.length; i++) {
                            meshes[indices[i]].material.opacity = 1;
                            //meshes[indices[i]].visible = true;
                        }
                    },
                    show_all: function () {
                        for (var i=0; i<N; i++) {
                            meshes[i].material.opacity = 1;
                            //meshes[i].visible = true;
                        }
                    },
                    set_size: function(width, height) {
                        renderer.setSize(width, height);
                    }
                };

			}



            function show_group_panos(elements, objects, N) {
                var controls = [];
                for (var i=0; i<objects.length; i++) {
                    controls.push(show_pano(elements[i], objects[i], N));
                }

                return {
                    controls: controls,
                    show: function (indices) {
                        for (var i=0; i<controls.length; i++) {
                            controls[i].show(indices);
                        }
                    },
                    show_all: function () {
                        for (var i=0; i<controls.length; i++) {
                            controls[i].show_all();
                        }
                    }
                };
            }

            function show_group_meshes(elements, objects, N) {
                var controls = [];
                for (var i=0; i<objects.length; i++) {
                    controls.push(show_mesh(elements[i], objects[i], N));
                }

                return {
                    controls: controls,
                    show: function (indices) {
                        for (var i=0; i<controls.length; i++) {
                            controls[i].show(indices);
                        }
                    },
                    show_all: function () {
                        for (var i=0; i<controls.length; i++) {
                            controls[i].show_all();
                        }
                    }
                };
            }



            function show_group(elements, objects, N) {
                var controls = [];
                for (var i=0; i<objects.length; i++) {
                    controls.push(show_object(elements[i], objects[i], N));
                }

                return {
                    controls: controls,
                    show: function (indices) {
                        for (var i=0; i<controls.length; i++) {
                            controls[i].show(indices);
                        }
                    },
                    show_all: function () {
                        for (var i=0; i<controls.length; i++) {
                            controls[i].show_all();
                        }
                    }
                };
            }

            // panoramas
            var panos = [
                "panoramas/color_0.png",
                "panoramas/color_7.png",
                "panoramas/color_21.png",
            ];
            // var human_control = show_group(
            //     document.getElementById("humans").getElementsByClassName("render_window"),
            //     [humans[0], humans[1], humans[2]],
            //     6
            // );

            var panos = show_group_panos(
                document.getElementById("input_panoramas").getElementsByClassName("render_window"),
                [panos[0], panos[1], panos[2]],
                6
            );

            //meshes
            var meshes_paths = [
                "ply/pred_0_mesh.obj",
                "ply/pred_7_mesh.obj",
                "ply/pred_21_mesh.obj",
            ];
            var non_coloured_meshes = show_group(
                document.getElementById("pred_meshes").getElementsByClassName("render_window"),
                [meshes_paths[0], meshes_paths[1], meshes_paths[2]],
                6
            );
            // var meshes = show_group_meshes(
            //     document.getElementById("point_clouds").getElementsByClassName("render_window"),
            //     [meshes_paths[0], meshes_paths[1], meshes_paths[2]],
            //     6
            // );
            
            // var human_checkboxes = document.querySelectorAll("#humans .controls input");
            // reset_checkboxes(human_checkboxes);
            // document.querySelector("#humans .controls").addEventListener(
            //     "change",
            //     function (ev) {
            //         if (ev.target.id == "humans_all") {
            //             Array.prototype.filter.call(
            //                 human_checkboxes,
            //                 (el) => el.id != "humans_all"
            //             ).forEach(function (el) {el.checked = false;});
            //         } else if (ev.target.checked) {
            //             human_checkboxes[0].checked = false;
            //         }

            //         var ids = new Set();
            //         if (human_checkboxes[0].checked) {
            //             ids = new Set([0, 1, 2, 3, 4, 5]);
            //         }
            //         var part_ids = [1, 2, 0, 4, 3, 5];
            //         for (var i=1; i<human_checkboxes.length; i++) {
            //             if (human_checkboxes[i].checked) {
            //                 ids.add(part_ids[i-1]);
            //             }
            //         }

            //         human_control.show(Array.from(ids));
            //     }
            // );
            // document.querySelector("#humans .controls button").addEventListener(
            //     "click",
            //     function (ev) {
            //         reset_checkboxes(human_checkboxes);
            //         var new_humans = random_choice(humans, 3);
            //         var render_windows = document.getElementById("humans").getElementsByClassName("render_window");
            //         Array.prototype.forEach.call(render_windows, function (r) {r.innerHTML = "";});
            //         human_control = show_group(
            //             render_windows,
            //             new_humans,
            //             6
            //         );
            //     }
            // );

            // // Planes
            // var planes = [
            //     "https://superquadrics.com/neural_parts/planes/10af5de930178a161596c26b5af806fe",
            //     "https://superquadrics.com/neural_parts/planes/1a32f10b20170883663e90eaf6b4ca52",
            //     "https://superquadrics.com/neural_parts/planes/1a6ad7a24bb89733f412783097373bdc",
            //     "https://superquadrics.com/neural_parts/planes/1b3c6b2fbcf834cf62b600da24e0965",
            //     "https://superquadrics.com/neural_parts/planes/1c26ecb4cd01759dc1006ed55bc1a3fc",
            //     "https://superquadrics.com/neural_parts/planes/284e6431669d46fd44797ce00623b3fd",
            //     "https://superquadrics.com/neural_parts/planes/2c3ba3f35c5d2b0ce77e43d0a92bdc06",
            //     "https://superquadrics.com/neural_parts/planes/315f523d0a924fb7ef70df8610b582b2",
            //     "https://superquadrics.com/neural_parts/planes/343a607d1604335fb4f192eea1889928",
            //     "https://superquadrics.com/neural_parts/planes/347d86d7001cef01232236eecec447b",
            //     "https://superquadrics.com/neural_parts/planes/351c9235749e398162147e00e97e28b5",
            //     "https://superquadrics.com/neural_parts/planes/3716ed4fa80dbf5f41392ab7a601818b",
            //     "https://superquadrics.com/neural_parts/planes/384e72f69e6f24404cb288947cda4a2c",
            //     "https://superquadrics.com/neural_parts/planes/440ac1b4ac3cbe114c3a35cee92bb95b",
            //     "https://superquadrics.com/neural_parts/planes/440e5ba74ac8124e9751c7a6f15617f4",
            //     "https://superquadrics.com/neural_parts/planes/48706d323b9041d5438a95791ca4064d",
            //     "https://superquadrics.com/neural_parts/planes/563cef4df464ddb1e153dd90dac45a6d",
            //     "https://superquadrics.com/neural_parts/planes/5c6590461085c93ea91e80f26309099e",
            //     "https://superquadrics.com/neural_parts/planes/60b5f5da40e0dd33579f6385fdd4245b",
            //     "https://superquadrics.com/neural_parts/planes/7b134f6573e7270fb0a79e28606cb167",
            //     "https://superquadrics.com/neural_parts/planes/92a83ecaa10e8d3f78e919a72d9a39e7",
            //     "https://superquadrics.com/neural_parts/planes/ed2aaca045fb1714cd4229f38ad0d015",
            //     "https://superquadrics.com/neural_parts/planes/f12eefbbefabe566ca8607f540cc62ba",
            // ];
            // var plane_control = show_group(
            //     document.getElementById("planes").getElementsByClassName("render_window"),
            //     [planes[7], planes[1], planes[2]],
            //     5
            // );
            // var plane_checkboxes = document.querySelectorAll("#planes .controls input");
            // reset_checkboxes(plane_checkboxes);
            // document.querySelector("#planes .controls").addEventListener(
            //     "change",
            //     function (ev) {
            //         if (ev.target.id == "planes_all") {
            //             Array.prototype.filter.call(
            //                 plane_checkboxes,
            //                 (el) => el.id != "planes_all"
            //             ).forEach(function (el) {el.checked = false;});
            //         } else if (ev.target.checked) {
            //             plane_checkboxes[0].checked = false;
            //         }

            //         var ids = new Set();
            //         if (plane_checkboxes[0].checked) {
            //             ids = new Set([0, 1, 2, 3, 4]);
            //         }
            //         var part_ids = [4, 0, 3, 2, 1];
            //         for (var i=1; i<plane_checkboxes.length; i++) {
            //             if (plane_checkboxes[i].checked) {
            //                 ids.add(part_ids[i-1]);
            //             }
            //         }

            //         plane_control.show(Array.from(ids));
            //     }
            // );
            // document.querySelector("#planes .controls button").addEventListener(
            //     "click",
            //     function (ev) {
            //         reset_checkboxes(plane_checkboxes);
            //         var new_planes = random_choice(planes, 3);
            //         var render_windows = document.getElementById("planes").getElementsByClassName("render_window");
            //         Array.prototype.forEach.call(render_windows, function (r) {r.innerHTML = "";});
            //         plane_control = show_group(
            //             render_windows,
            //             new_planes,
            //             5
            //         );
            //     }
            // );
        </script>
        <!-- <script>
            // Make the carousel for the comparisons
            var glide = new Glide(".glide", {
                type: "carousel",
                startAt: 0,
                perView: 1,
                autoplay: 2000
            }).mount();
        </script> -->
    </body>
</html>
